image: quay.io/ucsc_cgl/toil_ci_prebake:latest
# Note that we must run in a privileged container for our internal Docker daemon to come up.

variables:
  PYTHONIOENCODING: "utf-8"
  DEBIAN_FRONTEND: "noninteractive"
  TOIL_OWNER_TAG: "shared"
  MAIN_PYTHON_PKG: "python3.9"

before_script:
  # Log where we are running, in case some Kubernetes hosts are busted. IPs are assigned per host.
  - ip addr
  # Configure Docker to use a mirror for Docker Hub and restart the daemon
  # Set the registry as insecure because it is probably cluster-internal over plain HTTP.
  - |
    if [[ ! -z "${DOCKER_HUB_MIRROR}" ]] ; then
        echo "{\"registry-mirrors\": [\"${DOCKER_HUB_MIRROR}\"], \"insecure-registries\": [\"${DOCKER_HUB_MIRROR##*://}\"]}" | sudo tee /etc/docker/daemon.json
        export SINGULARITY_DOCKER_HUB_MIRROR="${DOCKER_HUB_MIRROR}"
    fi
  - startdocker || true
  - docker info
  - cat /etc/hosts
  - mkdir -p ~/.kube && cp "$GITLAB_SECRET_FILE_KUBE_CONFIG" ~/.kube/config
  - mkdir -p ~/.aws && cp "$GITLAB_SECRET_FILE_AWS_CREDENTIALS" ~/.aws/credentials
  # We need to make sure docker buildx create can't see the ~/.kube/config that we deploy. It has
  # a service account bearer token for auth and triggers https://github.com/docker/buildx/issues/267
  # where buildx can't use a bearer token from a kube config and falls back to anonymous instead
  # of using the system's service account.
  - KUBECONFIG=/dev/null docker buildx create --use --name toilbuilder --platform=linux/amd64,linux/arm64 --node=buildkit-amd64 --driver=kubernetes --driver-opt="nodeselector=kubernetes.io/arch=amd64"
  # Dump the builder info, and make sure it exists.
  - docker buildx inspect --bootstrap || (echo "Docker builder deployment can't be found in our Kubernetes namespace! Are we on the right Gitlab runner?" && exit 1)
  # This will hang if we can't talk to the builder
  - (echo "y" | docker buildx prune --keep-storage 80G) || true

after_script:
  # We need to clean up any files that Toil may have made via Docker that
  # aren't deletable by the Gitlab user. If we don't do this, Gitlab will try
  # and clean them up before running the next job on the runner, fail, and fail
  # that next job.
  - pwd
  - sudo rm -rf tmp
  - stopdocker || true

stages:
  - linting_and_dependencies
  - basic_tests
  - main_tests
  - integration


lint:
  stage: linting_and_dependencies
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && make prepare && make develop extras=[all] packages=htcondor
    - make mypy
    - make docs
    # - make diff_pydocstyle_report


cwl_dependency_is_stand_alone:
  stage: linting_and_dependencies
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && make prepare && make develop extras=[cwl]
    - make test tests=src/toil/test/docs/scriptsTest.py::ToilDocumentationTest::testCwlexample


wdl_dependency_is_stand_alone:
  stage: linting_and_dependencies
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && make prepare && make develop extras=[wdl]
    - make test tests=src/toil/test/wdl/toilwdlTest.py::ToilWdlIntegrationTest::testMD5sum

quick_test_offline:
  stage: basic_tests
  script:
    - ${MAIN_PYTHON_PKG} -m virtualenv venv
    - . venv/bin/activate
    - pip install -U pip wheel
    - make prepare
    - make develop extras=[aws,google,wdl]
    - TOIL_TEST_QUICK=True make test_offline

py37_appliance_build:
  stage: basic_tests
  script:
    - pwd
    - python3.7 -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && pip install pycparser && make develop extras=[all] packages='htcondor awscli'
    # This reads GITLAB_SECRET_FILE_QUAY_CREDENTIALS
    - python setup_gitlab_docker.py
    - make push_docker

py38_appliance_build:
  stage: basic_tests
  script:
    - pwd
    - python3.8 -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && pip install pycparser && make develop extras=[all] packages='htcondor awscli'
    # This reads GITLAB_SECRET_FILE_QUAY_CREDENTIALS
    - python setup_gitlab_docker.py
    - make push_docker

py39_appliance_build:
  stage: basic_tests
  script:
    - pwd
    - python3.9 -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && pip install pycparser && make develop extras=[all] packages='htcondor awscli'
    # This reads GITLAB_SECRET_FILE_QUAY_CREDENTIALS
    - python setup_gitlab_docker.py
    - make push_docker

py310_appliance_build:
  stage: basic_tests
  script:
    - pwd
    - python3.10 -m virtualenv venv && . venv/bin/activate && curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10 &&  pip install -U pip wheel && make prepare && pip install pycparser && make develop extras=[all] packages='htcondor awscli'
    # This reads GITLAB_SECRET_FILE_QUAY_CREDENTIALS
    - python setup_gitlab_docker.py
    - make push_docker

py310_main:
  stage: basic_tests
  script:
    - pwd
    - python3.10 -m virtualenv venv && . venv/bin/activate && curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10 && pip install -U pip wheel && make prepare && make develop extras=[all] packages=htcondor
    - make test tests="src/toil/test/src src/toil/test/utils"
    - TOIL_SKIP_DOCKER=true make test tests=src/toil/test/lib

batch_systems:
  stage: main_tests
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[all] packages='htcondor awscli'
    - wget https://github.com/ohsu-comp-bio/funnel/releases/download/0.10.1/funnel-linux-amd64-0.10.1.tar.gz
    - tar -xvf funnel-linux-amd64-0.10.1.tar.gz funnel
    - export FUNNEL_SERVER_USER=toil
    - export FUNNEL_SERVER_PASSWORD=$(openssl rand -hex 256)
    - |
      cat >funnel.conf <<EOF
      Server:
        BasicAuth:
          - User: ${FUNNEL_SERVER_USER}
            Password: ${FUNNEL_SERVER_PASSWORD}
      RPCClient:
        User: ${FUNNEL_SERVER_USER}
        Password: ${FUNNEL_SERVER_PASSWORD}
      LocalStorage:
        AllowedDirs:
          - $HOME/.aws
          - ./
      Compute: manual
      EOF
    - ./funnel server run -c funnel.conf &
    - ./funnel node run -c funnel.conf &
    - export TOIL_TES_ENDPOINT="http://127.0.0.1:8000"
    - export TOIL_TES_USER="${FUNNEL_SERVER_USER}"
    - export TOIL_TES_PASSWORD="${FUNNEL_SERVER_PASSWORD}"
    - make test tests="src/toil/test/batchSystems/batchSystemTest.py src/toil/test/mesos/MesosDataStructuresTest.py"
    - kill $(jobs -p) || true

slurm_test:
  stage: main_tests
  script:
    - pwd
    - cd contrib/slurm-test/
    - pip install docker-compose
    - ./slurm_test.sh

cwl_v1.0:
  stage: main_tests
  only: []
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[cwl,aws]
    - mypy --ignore-missing-imports --no-strict-optional $(pwd)/src/toil/cwl/cwltoil.py  # make this a separate linting stage
    - python setup_gitlab_docker.py  # login to increase the docker.io rate limit
    - make test tests=src/toil/test/cwl/cwlTest.py::CWLv10Test

cwl_v1.1:
  stage: main_tests
  only: []
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[cwl,aws]
    - python setup_gitlab_docker.py  # login to increase the docker.io rate limit
    - make test tests=src/toil/test/cwl/cwlTest.py::CWLv11Test

cwl_v1.2:
  stage: main_tests
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[cwl,aws]
    - python setup_gitlab_docker.py  # login to increase the docker.io rate limit
    - make test tests=src/toil/test/cwl/cwlTest.py::CWLv12Test

cwl_on_arm:
  stage: main_tests
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[cwl,aws]
    - python setup_gitlab_docker.py  # login to increase the docker.io rate limit
    # This reads GITLAB_SECRET_FILE_SSH_KEYS
    - python setup_gitlab_ssh.py
    - chmod 400 /root/.ssh/id_rsa
    - make test tests=src/toil/test/cwl/cwlTest.py::CWLOnARMTest

cwl_misc:
  stage: main_tests
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[cwl,aws]
    - python setup_gitlab_docker.py  # login to increase the docker.io rate limit
    - make test tests='src/toil/test/cwl/cwlTest.py -k "CWLWorkflowTest or cwl_small"'

cwl_v1.0_kubernetes:
  stage: main_tests
  only: []
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[cwl,aws,kubernetes]
    - export TOIL_KUBERNETES_OWNER=toiltest
    - export TOIL_AWS_SECRET_NAME=shared-s3-credentials
    - export TOIL_KUBERNETES_HOST_PATH=/data/scratch
    - export TOIL_WORKDIR=/var/lib/toil
    - export SINGULARITY_CACHEDIR=/var/lib/toil/singularity-cache
    - echo Singularity mirror is ${SINGULARITY_DOCKER_HUB_MIRROR}
    - mkdir -p ${TOIL_WORKDIR}
    - make test tests="src/toil/test/cwl/cwlTest.py::CWLv10Test::test_kubernetes_cwl_conformance src/toil/test/cwl/cwlTest.py::CWLv10Test::test_kubernetes_cwl_conformance_with_caching"

cwl_v1.1_kubernetes:
  stage: main_tests
  only: []
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[cwl,aws,kubernetes]
    - export TOIL_KUBERNETES_OWNER=toiltest
    - export TOIL_AWS_SECRET_NAME=shared-s3-credentials
    - export TOIL_KUBERNETES_HOST_PATH=/data/scratch
    - export TOIL_WORKDIR=/var/lib/toil
    - export SINGULARITY_CACHEDIR=/var/lib/toil/singularity-cache
    - mkdir -p ${TOIL_WORKDIR}
    - make test tests="src/toil/test/cwl/cwlTest.py::CWLv11Test::test_kubernetes_cwl_conformance src/toil/test/cwl/cwlTest.py::CWLv11Test::test_kubernetes_cwl_conformance_with_caching"

cwl_v1.2_kubernetes:
  stage: main_tests
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[cwl,aws,kubernetes]
    - export TOIL_KUBERNETES_OWNER=toiltest
    - export TOIL_AWS_SECRET_NAME=shared-s3-credentials
    - export TOIL_KUBERNETES_HOST_PATH=/data/scratch
    - export TOIL_WORKDIR=/var/lib/toil
    - export SINGULARITY_CACHEDIR=/var/lib/toil/singularity-cache
    - mkdir -p ${TOIL_WORKDIR}
    - make test tests="src/toil/test/cwl/cwlTest.py::CWLv12Test::test_kubernetes_cwl_conformance src/toil/test/cwl/cwlTest.py::CWLv12Test::test_kubernetes_cwl_conformance_with_caching"
  artifacts:
    reports:
      junit: "*.junit.xml"
    paths:
      - "*.junit.xml"
    when: always
    expire_in: 14 days

wdl:
  stage: main_tests
  script:
    - pwd
    - apt update && apt install -y default-jre
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[all]
    - which java &> /dev/null || { echo >&2 "Java is not installed.  Install java to run these tests."; exit 1; }
    - make test tests="src/toil/test/wdl/toilwdlTest.py src/toil/test/wdl/builtinTest.py"  # needs java (default-jre) to run "GATK.jar"

jobstore_and_provisioning:
  stage: main_tests
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[all] packages=htcondor
    - make test tests="src/toil/test/lib/aws/ src/toil/test/jobStores/jobStoreTest.py src/toil/test/sort/sortTest.py src/toil/test/provisioners/aws/awsProvisionerTest.py src/toil/test/provisioners/clusterScalerTest.py"
#    - make test tests=src/toil/test/provisioners/gceProvisionerTest.py
# https://ucsc-ci.com/databiosphere/toil/-/jobs/38672
# guessing decorators are masking class as function?  ^  also, abstract class is run as normal test?  should hide.

integration:
  stage: integration
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[all] packages='htcondor awscli'
    - export TOIL_TEST_INTEGRATIVE=True
    - export TOIL_AWS_KEYNAME=id_rsa
    - export TOIL_AWS_ZONE=us-west-2a
    # This reads GITLAB_SECRET_FILE_SSH_KEYS
    - python setup_gitlab_ssh.py
    - chmod 400 /root/.ssh/id_rsa
    # Test integration with job stores
    # Test server and its integration with AWS
    - make test tests="src/toil/test/jobStores/jobStoreTest.py src/toil/test/server"

provisioner_integration:
  stage: integration
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[all] packages='htcondor awscli'
    - python setup_gitlab_ssh.py && chmod 400 /root/.ssh/id_rsa
    - echo $'Host *\n    AddressFamily inet' > /root/.ssh/config
    - export LIBPROCESS_IP=127.0.0.1
    - python setup_gitlab_docker.py
    - export TOIL_TEST_INTEGRATIVE=True; export TOIL_AWS_KEYNAME=id_rsa; export TOIL_AWS_ZONE=us-west-2a
    # This reads GITLAB_SECRET_FILE_SSH_KEYS
    - python setup_gitlab_ssh.py
    - make test tests="src/toil/test/sort/sortTest.py src/toil/test/provisioners/clusterScalerTest.py src/toil/test/utils/utilsTest.py::UtilsTest::testAWSProvisionerUtils src/toil/test/provisioners/aws/awsProvisionerTest.py"
#    - make test tests=src/toil/test/provisioners/gceProvisionerTest.py  # needs env vars set to run

google_jobstore:
  stage: integration
  script:
    - pwd
    - ${MAIN_PYTHON_PKG} -m virtualenv venv && . venv/bin/activate && pip install -U pip wheel && make prepare && make develop extras=[all] packages='htcondor awscli'
    - python setup_gitlab_ssh.py && chmod 400 /root/.ssh/id_rsa
    - echo $'Host *\n    AddressFamily inet' > /root/.ssh/config
    - export LIBPROCESS_IP=127.0.0.1
    - export TOIL_TEST_INTEGRATIVE=True
    - export GOOGLE_APPLICATION_CREDENTIALS=$GOOGLE_CREDENTIALS
    - export TOIL_GOOGLE_KEYNAME=id_rsa
    - export TOIL_GOOGLE_PROJECTID=toil-dev
    - make test tests=src/toil/test/jobStores/jobStoreTest.py::GoogleJobStoreTest

# Cactus-on-Kubernetes integration (as a script and not a pytest test)
cactus_integration:
  stage: integration
  script:
    - set -e
    - ${MAIN_PYTHON_PKG} -m virtualenv --system-site-packages venv
    - . venv/bin/activate
    - pip install -U pip wheel
    - pip install .[aws,kubernetes]
    - export TOIL_KUBERNETES_OWNER=toiltest
    - export TOIL_AWS_SECRET_NAME=shared-s3-credentials
    - export TOIL_KUBERNETES_HOST_PATH=/data/scratch
    - export TOIL_WORKDIR=/var/lib/toil
    - export SINGULARITY_CACHEDIR=/var/lib/toil/singularity-cache
    - mkdir -p ${TOIL_WORKDIR}
    - BUCKET_NAME=toil-test-$RANDOM-$RANDOM-$RANDOM
    - cd
    - git clone https://github.com/ComparativeGenomicsToolkit/cactus.git --recursive
    - cd cactus
    - git fetch origin
    - git checkout f5adf4013326322ae58ef1eccb8409b71d761583
    - git submodule update --init --recursive
    # We can't use setuptools 66 on Ubuntu due to https://github.com/pypa/setuptools/issues/3772
    - pip install --upgrade 'setuptools<66' pip
    - pip install --upgrade .
    - pip install --upgrade numpy psutil # Cactus installs an old psutil that Toil isn't compatible with. TODO: Do we really need Numpy?
    - toil clean aws:us-west-2:${BUCKET_NAME}
    - time cactus --setEnv SINGULARITY_DOCKER_HUB_MIRROR --batchSystem kubernetes --retryCount=3 --consCores 2 --binariesMode singularity --clean always aws:us-west-2:${BUCKET_NAME} examples/evolverMammals.txt examples/evolverMammals.hal --root mr --defaultDisk "8G" --logDebug
